# Structural Representation-Guided GAN for Cloud Removal

Implementation of the IEEE GRSL 2025 paper: "Structural Representation-Guided GAN for Remote Sensing Image Cloud Removal"

## ğŸ“‹ Overview

This project implements a novel cloud removal framework for optical remote sensing images using:

- **Structural representation guidance** through gradient and structure branches
- **Generative Adversarial Network (GAN)** with LSGAN loss
- **Multi-temporal auxiliary images** for reliable thick cloud removal
- **Cloud Matting synthesis** for realistic training data generation

## ğŸ¯ Key Features

- âœ… Complete implementation of the paper's architecture
- âœ… Structural representation branches (gradient + structure)
- âœ… Error feedback fusion mechanism
- âœ… GAN-based adversarial training
- âœ… Multi-temporal image support
- âœ… Cloud Matting synthesis algorithm
- âœ… Comprehensive evaluation metrics (PSNR, SSIM, CC, RMSE)
- âœ… TensorBoard logging
- âœ… Checkpoint management

## ğŸ“ Project Structure

```
cloud_removal_project/
â”œâ”€â”€ config.py                 # Configuration settings
â”œâ”€â”€ train.py                  # Training script
â”œâ”€â”€ test.py                   # Testing and inference
â”œâ”€â”€ prepare_dataset.py        # Dataset preparation
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generator.py         # Cloud removal network
â”‚   â”œâ”€â”€ discriminator.py     # Discriminator network
â”‚   â””â”€â”€ losses.py            # Loss functions
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py       # Dataset and dataloaders
â”‚   â”œâ”€â”€ cloud_synthesis.py   # Cloud Matting synthesis
â”‚   â””â”€â”€ metrics.py           # Evaluation metrics
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ SEN12MS-CR-raw/      # Downloaded .tar.gz files
â”‚   â””â”€â”€ SEN12MS-CR/          # Extracted dataset
â”œâ”€â”€ checkpoints/              # Model checkpoints
â”œâ”€â”€ logs/                     # TensorBoard logs
â””â”€â”€ test_results/             # Test outputs
```

## ğŸš€ Quick Start

### 1. Clone and Setup

```bash
# Create project directory
mkdir cloud_removal_project && cd cloud_removal_project

# Create all necessary subdirectories
mkdir -p data/SEN12MS-CR-raw data/SEN12MS-CR models utils checkpoints logs test_results

# Create __init__.py files
touch models/__init__.py utils/__init__.py
```

### 2. Install Dependencies

```bash
# Create virtual environment (recommended)
conda create -n cloud_removal python=3.9
conda activate cloud_removal

# Install PyTorch (adjust for your CUDA version)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Install other dependencies
pip install -r requirements.txt
```

### 3. Prepare Dataset

**You already have the dataset downloaded!** Now extract it:

```bash
# Move your downloaded .tar.gz files
mv /path/to/your/downloads/*.tar.gz ./data/SEN12MS-CR-raw/

# Extract dataset (this will take a while)
python prepare_dataset.py
```

**Note:** You can start with just 1-2 seasons if disk space is limited:

- Priority: Extract `ROIs1868_summer_s2.tar.gz` and `ROIs1158_spring_s2.tar.gz`

### 4. Train the Model

```bash
# Start training
python train.py

# Monitor with TensorBoard (in another terminal)
tensorboard --logdir=./logs
```

### 5. Test the Model

```bash
# Test on test set
python test.py

# Results will be saved in ./test_results/
```

## âš™ï¸ Configuration

Edit `config.py` to customize training:

```python
# Key parameters
BATCH_SIZE = 4              # Reduce to 2 or 1 if OOM
IMG_SIZE = 256              # Image size
NUM_EPOCHS = 100            # Training epochs
LEARNING_RATE = 0.0002      # Learning rate

# Loss weights
LAMBDA_REC = 1.0           # Reconstruction
LAMBDA_PERC = 0.1          # Perceptual
LAMBDA_STYLE = 250.0       # Style
LAMBDA_STRU = 1.0          # Structure
LAMBDA_GRAD = 1.0          # Gradient
LAMBDA_GAN = 0.01          # GAN
```

## ğŸ“Š Expected Results

After training on SEN12MS-CR dataset:

| Metric | Expected Value |
| ------ | -------------- |
| PSNR   | 32-35 dB       |
| SSIM   | 0.90-0.94      |
| CC     | 0.93-0.96      |
| RMSE   | 0.02-0.04      |

## ğŸ”§ Troubleshooting

### Out of Memory (OOM)

```python
# In config.py
BATCH_SIZE = 1              # Reduce batch size
IMG_SIZE = 128              # Reduce image size
```

### Slow Training

```python
# In train.py, modify create_dataloaders
train_loader, val_loader, test_loader = create_dataloaders(config, num_workers=2)
```

### Dataset Not Loading

```bash
# Verify extraction
python prepare_dataset.py

# Check for .tif files
find data/SEN12MS-CR/ -name "*.tif" | wc -l
```

## ğŸ“ Using Custom Images

```python
from config import Config
from test import Tester

config = Config()
tester = Tester(config, checkpoint_path='checkpoints/best_model.pth')

# Infer on custom image
tester.infer_single_image(
    cloudy_path='path/to/cloudy.png',
    temporal_path='path/to/temporal.png',
    save_path='output_clean.png'
)
```

## ğŸ“ Citation

If you use this code, please cite the original paper:

```bibtex
@article{yang2025structural,
  title={Structural Representation-Guided GAN for Remote Sensing Image Cloud Removal},
  author={Yang, Jiajun and Wang, Wenjing and Chen, Keyan and Liu, Liqin and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Geoscience and Remote Sensing Letters},
  volume={22},
  pages={6002105},
  year={2025},
  publisher={IEEE}
}
```

## ğŸ“¦ Model Architecture

### Generator (Cloud Removal Network)

- **Encoder**: 6-level encoder with multi-scale feature extraction
- **Gradient Branch**: First 3 encoder levels â†’ gradient map prediction
- **Structure Branch**: Last 3 encoder levels â†’ structure map prediction
- **Error Feedback**: Fuses branch features into decoder
- **Decoder**: 6-level decoder with skip connections

### Discriminator

- 5-layer convolutional network
- PatchGAN architecture
- LSGAN loss for stable training

### Loss Functions

1. **Reconstruction Loss** (L1): Pixel-level consistency
2. **Perceptual Loss**: VGG16-based feature matching
3. **Style Loss**: Gram matrix matching
4. **Structure Loss**: Edge/structure map consistency
5. **Gradient Loss**: Gradient map consistency
6. **Adversarial Loss**: LSGAN loss

## ğŸ” Training Details

- **Optimizer**: Adam (lr=0.0002, Î²1=0.5, Î²2=0.999)
- **Batch Size**: 4
- **Epochs**: 100
- **Image Size**: 256Ã—256
- **Data Augmentation**: Random flip, rotation
- **Mixed Training**: Synthetic + real cloud images

## ğŸ“ˆ Monitoring Training

TensorBoard logs include:

- Training losses (G_total, G_rec, G_perc, G_style, G_stru, G_grad, G_gan, D)
- Validation metrics (PSNR, SSIM, CC, RMSE)
- Sample images

```bash
tensorboard --logdir=./logs --port=6006
```

## ğŸ’¾ Checkpoints

Models are saved:

- Every 5 epochs: `checkpoint_epoch_X.pth`
- Best model: `best_model.pth` (highest validation PSNR)
- Latest: `checkpoint.pth` (for resuming training)

## ğŸ¤ Contributing

Feel free to open issues or submit pull requests for:

- Bug fixes
- Performance improvements
- Additional features
- Documentation improvements

## ğŸ“„ License

This implementation is for research purposes. Please refer to the original paper for licensing information.

## ğŸ™ Acknowledgments

- Original paper authors: Yang et al.
- SEN12MS-CR dataset: TUM MÃ¼nchen
- PyTorch community

## ğŸ“§ Contact

For questions or issues, please open a GitHub issue or contact the repository maintainer.

---

**Note**: This implementation requires significant computational resources. A GPU with at least 8GB VRAM is recommended for training.
